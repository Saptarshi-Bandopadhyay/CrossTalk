{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IzvD4YBbsmmx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From d:\\Documents\\machine_learning\\DL\\neural_machine_translation\\encodeco_attention\\venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
        "import keras\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KewRilHq1aq",
        "outputId": "b3525fdb-779e-43ce-85da-f13044da1fc3"
      },
      "outputs": [],
      "source": [
        "url = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
        "path = keras.utils.get_file(\"spa-eng.zip\", origin=url, cache_dir=\"datasets\",\n",
        " extract=True)\n",
        "text = (Path(path).with_name(\"spa-eng\") / \"spa.txt\").read_text(encoding='utf-8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dChe_mq-tYxP"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0jENej0-uYws"
      },
      "outputs": [],
      "source": [
        "text = text.replace(\"¡\", \"\").replace(\"¿\", \"\")\n",
        "pairs = [line.split(\"\\t\") for line in text.splitlines()]\n",
        "np.random.shuffle(pairs)\n",
        "sentences_en, sentences_es = zip(*pairs) # separates the pairs into 2 lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "We0gNFhju6W9"
      },
      "outputs": [],
      "source": [
        "vocab_size = 5000\n",
        "max_length = 50\n",
        "text_vec_layer_en = keras.layers.TextVectorization(\n",
        " vocab_size, output_sequence_length=max_length)\n",
        "text_vec_layer_es = keras.layers.TextVectorization(\n",
        " vocab_size, output_sequence_length=max_length)\n",
        "text_vec_layer_en.adapt(sentences_en)\n",
        "text_vec_layer_es.adapt([f\"startofseq {s} endofseq\" for s in sentences_es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = np.array(text_vec_layer_es.get_vocabulary())\n",
        "np.save('vocabulary.npy', a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = np.load('vocabulary.npy')\n",
        "list(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2QG1f9TQvI9A"
      },
      "outputs": [],
      "source": [
        "X_train = tf.constant(sentences_en[:100_000])\n",
        "X_valid = tf.constant(sentences_en[100_000:])\n",
        "X_train_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[:100_000]])\n",
        "X_valid_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[100_000:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "odd9PC0YvNNT"
      },
      "outputs": [],
      "source": [
        "Y_train = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[:100_000]])\n",
        "Y_valid = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[100_000:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xB_8cn7CvP1K"
      },
      "outputs": [],
      "source": [
        "encoder_inputs = keras.layers.Input(shape=[], dtype=tf.string)\n",
        "decoder_inputs = keras.layers.Input(shape=[], dtype=tf.string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QZTqUIdYvR-m"
      },
      "outputs": [],
      "source": [
        "embed_size = 128\n",
        "encoder_input_ids = text_vec_layer_en(encoder_inputs)\n",
        "decoder_input_ids = text_vec_layer_es(decoder_inputs)\n",
        "encoder_embedding_layer = keras.layers.Embedding(vocab_size, embed_size,\n",
        " mask_zero=True)\n",
        "decoder_embedding_layer = keras.layers.Embedding(vocab_size, embed_size,\n",
        " mask_zero=True)\n",
        "encoder_embeddings = encoder_embedding_layer(encoder_input_ids)\n",
        "decoder_embeddings = decoder_embedding_layer(decoder_input_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Mp_W4xSjvUJI"
      },
      "outputs": [],
      "source": [
        "encoder = keras.layers.Bidirectional(\n",
        "    keras.layers.LSTM(256, return_sequences=True, return_state=True))\n",
        "encoder_outputs, *encoder_state = encoder(encoder_embeddings)\n",
        "encoder_state = [tf.concat(encoder_state[::2], axis=-1),  # short-term (0 & 2)\n",
        "                 tf.concat(encoder_state[1::2], axis=-1)]  # long-term (1 & 3)\n",
        "decoder = keras.layers.LSTM(512, return_sequences=True)\n",
        "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HXwJI1u6vYyN"
      },
      "outputs": [],
      "source": [
        "attention_layer = keras.layers.Attention()\n",
        "attention_outputs = attention_layer([decoder_outputs, encoder_outputs])\n",
        "output_layer = keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
        "Y_proba = output_layer(attention_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a5NC3MgvbMA",
        "outputId": "9c6b3938-6e13-4013-aa78-4ca55b2120ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "3125/3125 [==============================] - 157s 45ms/step - loss: 3.7472 - accuracy: 0.3770 - val_loss: 2.5078 - val_accuracy: 0.5249\n",
            "Epoch 2/10\n",
            "3125/3125 [==============================] - 107s 34ms/step - loss: 2.0090 - accuracy: 0.5894 - val_loss: 1.8274 - val_accuracy: 0.6178\n",
            "Epoch 3/10\n",
            "3125/3125 [==============================] - 111s 35ms/step - loss: 1.4978 - accuracy: 0.6629 - val_loss: 1.6105 - val_accuracy: 0.6493\n",
            "Epoch 4/10\n",
            "3125/3125 [==============================] - 110s 35ms/step - loss: 1.2443 - accuracy: 0.7043 - val_loss: 1.5317 - val_accuracy: 0.6638\n",
            "Epoch 5/10\n",
            "3125/3125 [==============================] - 109s 35ms/step - loss: 1.0744 - accuracy: 0.7342 - val_loss: 1.5017 - val_accuracy: 0.6729\n",
            "Epoch 6/10\n",
            "3125/3125 [==============================] - 112s 36ms/step - loss: 0.9448 - accuracy: 0.7585 - val_loss: 1.4965 - val_accuracy: 0.6758\n",
            "Epoch 7/10\n",
            "3125/3125 [==============================] - 109s 35ms/step - loss: 0.8402 - accuracy: 0.7795 - val_loss: 1.5144 - val_accuracy: 0.6773\n",
            "Epoch 8/10\n",
            "3125/3125 [==============================] - 111s 35ms/step - loss: 0.7541 - accuracy: 0.7979 - val_loss: 1.5502 - val_accuracy: 0.6782\n",
            "Epoch 9/10\n",
            "3125/3125 [==============================] - 112s 36ms/step - loss: 0.6824 - accuracy: 0.8131 - val_loss: 1.5796 - val_accuracy: 0.6770\n",
            "Epoch 10/10\n",
            "3125/3125 [==============================] - 111s 36ms/step - loss: 0.6222 - accuracy: 0.8270 - val_loss: 1.6223 - val_accuracy: 0.6744\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bc07ee671f0>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
        "                       outputs=[Y_proba])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit((X_train, X_train_dec), Y_train, epochs=10,\n",
        "          validation_data=((X_valid, X_valid_dec), Y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "M4MxKWJavdkZ"
      },
      "outputs": [],
      "source": [
        "def translate(sentence_en):\n",
        "    translation = \"\"\n",
        "    for word_idx in range(max_length):\n",
        "        X = tf.constant([sentence_en]) # encoder input\n",
        "        X_dec = tf.constant([\"startofseq \" + translation]) # decoder input\n",
        "        y_proba = model.predict((X, X_dec))[0, word_idx] # last token's probas\n",
        "        predicted_word_id = np.argmax(y_proba)\n",
        "        predicted_word = text_vec_layer_es.get_vocabulary()[predicted_word_id]\n",
        "        if predicted_word == \"endofseq\":\n",
        "            break\n",
        "        translation += \" \" + predicted_word\n",
        "    return translation.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "zHgwpFsY9uSz",
        "outputId": "0a177341-99c1-42b6-ea25-e8c3e40b449d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'me gusta el fútbol'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translate(\"I like soccer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "nE0Db4JG91ln",
        "outputId": "8408a388-6b4a-4c2e-eff4-05af819deec9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'me gusta viajar y también a la playa a muchas niñas'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translate(\"I like to travel and also going to the beach with many girls\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "uUvLmS0i94E7"
      },
      "outputs": [],
      "source": [
        "model.save(\"encodeco_attention_nmt_5000.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlZINQKZ-H8b"
      },
      "outputs": [],
      "source": [
        "loaded_model = keras.saving.load_model(\"encodeco_attention_nmt_5000.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1JjIlIY0OB6R"
      },
      "outputs": [],
      "source": [
        "def translate(sentence_en):\n",
        "    translation = \"\"\n",
        "    for word_idx in range(max_length):\n",
        "        X = tf.constant([sentence_en]) # encoder input\n",
        "        X_dec = tf.constant([\"startofseq \" + translation]) # decoder input\n",
        "        y_proba = loaded_model.predict((X, X_dec))[0, word_idx] # last token's probas\n",
        "        predicted_word_id = np.argmax(y_proba)\n",
        "        predicted_word = text_vec_layer_es.get_vocabulary()[predicted_word_id]\n",
        "        if predicted_word == \"endofseq\":\n",
        "            break\n",
        "        translation += \" \" + predicted_word\n",
        "    return translation.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW2lf8RZOIKe",
        "outputId": "75883365-1b1f-4b23-c85f-a43c244ccf2d"
      },
      "outputs": [],
      "source": [
        "text_vec_layer_en.get_vocabulary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anfG1N_pOLr3"
      },
      "outputs": [],
      "source": [
        "translate(\"I like doing homework\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-UvwzRBwPako"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.15.0\n"
          ]
        }
      ],
      "source": [
        "print(keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
