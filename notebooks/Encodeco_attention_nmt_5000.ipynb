{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzvD4YBbsmmx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KewRilHq1aq",
        "outputId": "b3525fdb-779e-43ce-85da-f13044da1fc3"
      },
      "outputs": [],
      "source": [
        "url = \"https://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\"\n",
        "path = keras.utils.get_file(\"spa-eng.zip\", origin=url, cache_dir=\"datasets\",\n",
        " extract=True)\n",
        "text = (Path(path).with_name(\"spa-eng\") / \"spa.txt\").read_text(encoding='utf-8') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0jENej0-uYws"
      },
      "outputs": [],
      "source": [
        "text = text.replace(\"¡\", \"\").replace(\"¿\", \"\")\n",
        "pairs = [line.split(\"\\t\") for line in text.splitlines()]\n",
        "np.random.shuffle(pairs)\n",
        "sentences_en, sentences_es = zip(*pairs) # separates the pairs into 2 lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "We0gNFhju6W9"
      },
      "outputs": [],
      "source": [
        "vocab_size = 6000\n",
        "max_length = 50\n",
        "text_vec_layer_en = keras.layers.TextVectorization(\n",
        " vocab_size, output_sequence_length=max_length)\n",
        "text_vec_layer_es = keras.layers.TextVectorization(\n",
        " vocab_size, output_sequence_length=max_length)\n",
        "text_vec_layer_en.adapt(sentences_en)\n",
        "text_vec_layer_es.adapt([f\"startofseq {s} endofseq\" for s in sentences_es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = np.array(text_vec_layer_es.get_vocabulary())\n",
        "np.save('vocabulary.npy', a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "a = np.load('vocabulary.npy')\n",
        "list(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2QG1f9TQvI9A"
      },
      "outputs": [],
      "source": [
        "X_train = tf.constant(sentences_en[:100_000])\n",
        "X_valid = tf.constant(sentences_en[100_000:])\n",
        "X_train_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[:100_000]])\n",
        "X_valid_dec = tf.constant([f\"startofseq {s}\" for s in sentences_es[100_000:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "odd9PC0YvNNT"
      },
      "outputs": [],
      "source": [
        "Y_train = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[:100_000]])\n",
        "Y_valid = text_vec_layer_es([f\"{s} endofseq\" for s in sentences_es[100_000:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xB_8cn7CvP1K"
      },
      "outputs": [],
      "source": [
        "encoder_inputs = keras.layers.Input(shape=[], dtype=tf.string)\n",
        "decoder_inputs = keras.layers.Input(shape=[], dtype=tf.string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QZTqUIdYvR-m"
      },
      "outputs": [],
      "source": [
        "embed_size = 128\n",
        "encoder_input_ids = text_vec_layer_en(encoder_inputs)\n",
        "decoder_input_ids = text_vec_layer_es(decoder_inputs)\n",
        "encoder_embedding_layer = keras.layers.Embedding(vocab_size, embed_size,\n",
        " mask_zero=True)\n",
        "decoder_embedding_layer = keras.layers.Embedding(vocab_size, embed_size,\n",
        " mask_zero=True)\n",
        "encoder_embeddings = encoder_embedding_layer(encoder_input_ids)\n",
        "decoder_embeddings = decoder_embedding_layer(decoder_input_ids)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Mp_W4xSjvUJI"
      },
      "outputs": [],
      "source": [
        "encoder = keras.layers.Bidirectional(\n",
        "    keras.layers.LSTM(256, return_sequences=True, return_state=True, dropout=0.3))\n",
        "encoder_outputs, *encoder_state = encoder(encoder_embeddings)\n",
        "encoder_state = [tf.concat(encoder_state[::2], axis=-1),  # short-term (0 & 2)\n",
        "                 tf.concat(encoder_state[1::2], axis=-1)]  # long-term (1 & 3)\n",
        "decoder = keras.layers.LSTM(512, return_sequences=True, dropout=0.2)\n",
        "decoder_outputs = decoder(decoder_embeddings, initial_state=encoder_state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HXwJI1u6vYyN"
      },
      "outputs": [],
      "source": [
        "attention_layer = keras.layers.Attention()\n",
        "attention_outputs = attention_layer([decoder_outputs, encoder_outputs])\n",
        "output_layer = keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
        "Y_proba = output_layer(attention_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a5NC3MgvbMA",
        "outputId": "9c6b3938-6e13-4013-aa78-4ca55b2120ff"
      },
      "outputs": [],
      "source": [
        "model = keras.Model(inputs=[encoder_inputs, decoder_inputs],\n",
        "                       outputs=[Y_proba])\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit((X_train, X_train_dec), Y_train, epochs=20,\n",
        "          validation_data=((X_valid, X_valid_dec), Y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "M4MxKWJavdkZ"
      },
      "outputs": [],
      "source": [
        "def translate(sentence_en):\n",
        "    translation = \"\"\n",
        "    for word_idx in range(max_length):\n",
        "        X = tf.constant([sentence_en]) # encoder input\n",
        "        X_dec = tf.constant([\"startofseq \" + translation]) # decoder input\n",
        "        y_proba = model.predict((X, X_dec))[0, word_idx] # last token's probas\n",
        "        predicted_word_id = np.argmax(y_proba)\n",
        "        predicted_word = text_vec_layer_es.get_vocabulary()[predicted_word_id]\n",
        "        if predicted_word == \"endofseq\":\n",
        "            break\n",
        "        translation += \" \" + predicted_word\n",
        "    return translation.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "zHgwpFsY9uSz",
        "outputId": "0a177341-99c1-42b6-ea25-e8c3e40b449d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'me gusta el fútbol'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "translate(\"I like soccer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "uUvLmS0i94E7"
      },
      "outputs": [],
      "source": [
        "model.save(\"encodeco_attention_nmt_6000.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RlZINQKZ-H8b"
      },
      "outputs": [],
      "source": [
        "loaded_model = keras.saving.load_model(\"encodeco_attention_nmt_6000.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1JjIlIY0OB6R"
      },
      "outputs": [],
      "source": [
        "def translate(sentence_en):\n",
        "    translation = \"\"\n",
        "    for word_idx in range(max_length):\n",
        "        X = tf.constant([sentence_en]) # encoder input\n",
        "        X_dec = tf.constant([\"startofseq \" + translation]) # decoder input\n",
        "        y_proba = loaded_model.predict((X, X_dec))[0, word_idx] # last token's probas\n",
        "        predicted_word_id = np.argmax(y_proba)\n",
        "        predicted_word = text_vec_layer_es.get_vocabulary()[predicted_word_id]\n",
        "        if predicted_word == \"endofseq\":\n",
        "            break\n",
        "        translation += \" \" + predicted_word\n",
        "    return translation.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anfG1N_pOLr3"
      },
      "outputs": [],
      "source": [
        "translate(\"I like doing homework\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
